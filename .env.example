# Backend environment example for temporary Azure/App Service deployment

# 1) Required
OPENAI_API_KEY=your-openai-api-key

# 2) Report generation and storage (temporary, non-persistent)
# Set to "memory" to avoid storing PDFs on the server; users download once and keep locally.
STORE_REPORTS=memory
# Use OS temp on Azure/Linux so any transient writes are in /tmp (auto-cleaned on restart).
OUTPUT_DIR=/tmp
# Do not persist extracted bank transaction JSON artifacts by default.
SAVE_TX_JSON=false

# 3) Optional server settings
#PORT=5000
# Maximum upload size in MB (if you wire this into app.py)
#MAX_CONTENT_LENGTH_MB=16

# Notes:
# - With STORE_REPORTS=memory, the API writes a PDF to OUTPUT_DIR, serves it once via /download-temp/<token>, then deletes the file.
# - For multi-instance deployments, one-time tokens are instance-local; fine for free/single instance. For scale-out, use sticky sessions or persistent storage.
